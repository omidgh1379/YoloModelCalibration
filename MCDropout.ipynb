{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.nn.modules import MCDropout\n",
    "#from ultralytics.data.dataset import YOLODataset\n",
    "from torch.utils.data import DataLoader\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "#from ultralytics.utils.loss import v8DetectionLoss\n",
    "from torchvision.ops import box_iou\n",
    "from torch.optim import Adam\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import RMSprop\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Rprop\n",
    "from torch.optim import NAdam\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from ultralytics.data.dataset import YOLODataset\n",
    "from ultralytics.utils.ops import non_max_suppression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_validation_loader' from 'loaddata' (/home/omid/loaddata.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mloaddata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_validation_loader\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_validation_loader' from 'loaddata' (/home/omid/loaddata.py)"
     ]
    }
   ],
   "source": [
    "from loaddata import create_validation_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implemntation of Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class YOLOWithDropout(nn.Module):\n",
    "\n",
    "    def __init__(self , original_model , n_samples = 10):\n",
    "        super(YOLOWithDropout, self).__init__()\n",
    "        self.model = original_model.model\n",
    "        \n",
    "        self.n_samples = n_samples\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    def enable_dropout(self):\n",
    "            \"\"\"Activate dropout during inference while keeping batch norm in eval mode.\"\"\"\n",
    "            self.model.eval()\n",
    "            for module in self.model.modules():\n",
    "                if isinstance(module, MCDropout):\n",
    "                    module.train()\n",
    "            return True\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    def evaluate_dropout(self, val_loader):\n",
    "        \n",
    "        \n",
    "\n",
    "        all_logits_standard = []\n",
    "        all_labels_standard = []\n",
    "        \n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch in val_loader:\n",
    "\n",
    "                input = batch['img'].to(torch.float32) / 255.0  # Normalize input to [0, 1] range\n",
    "                input = input \n",
    "                targets = {\n",
    "                    'cls' : batch['cls'] , \n",
    "                    'bboxes' : batch['bboxes'] , \n",
    "                    'batch_idx' : batch['batch_idx']\n",
    "                }\n",
    "\n",
    "                outputs = self.model(input)\n",
    "                outputs = outputs[0][0].transpose(-1, -2)\n",
    "                #print('outputs shape is for normal ',outputs.shape)\n",
    "                logits  , labels = self._match_targets_to_outputs(outputs , targets)\n",
    "                if logits is not None and labels is not None:\n",
    "                    all_logits_standard.append(logits)\n",
    "                    all_labels_standard.append(labels)\n",
    "                    \n",
    "                    \n",
    "        \n",
    "        all_logits_standard = torch.cat(all_logits_standard , dim = 0)\n",
    "        all_labels_standard = torch.cat(all_labels_standard , dim = 0).long()\n",
    "        \n",
    "\n",
    "        ece = _ECE_criterion()\n",
    "        nll_criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        ece_standard = ece(all_logits_standard , all_labels_standard.squeeze(1))\n",
    "        nll_standard = nll_criterion(all_logits_standard , all_labels_standard.squeeze(1))\n",
    "        \n",
    "        print(f'ECE standard is : {ece_standard}')\n",
    "        print(f'NLL standard is : {nll_standard}')\n",
    "\n",
    "        # Enable dropout for Monte Carlo sampling\n",
    "        self.enable_dropout()\n",
    "             \n",
    "        all_logits_mc = []\n",
    "        all_labels_mc = []\n",
    "        \n",
    "        for i,batch in enumerate(val_loader):\n",
    "            input = batch['img'].to(torch.float32)  / 255.0  # Normalize input to [0, 1] range\n",
    "\n",
    "            print('input shape is ',input.shape)\n",
    "\n",
    "            targets = {\n",
    "                    'cls': batch['cls'],\n",
    "                    'bboxes': batch['bboxes'],\n",
    "                    'batch_idx': batch['batch_idx']\n",
    "                }\n",
    "\n",
    "            outputs = []\n",
    "            # Collect outputs from multiple forward passes\n",
    "            \n",
    "            for _ in range(self.n_samples):\n",
    "                output = self.model(input)\n",
    "                output = output[0][0].transpose(-1, -2)\n",
    "                \n",
    "                \n",
    "                outputs.append(output)\n",
    "\n",
    "            outputs = torch.stack(outputs , dim = 0 )\n",
    "            mean_outputs = torch.mean(outputs , dim = 0)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "            \n",
    "            logits,  labels = self._match_targets_to_outputs(mean_outputs, targets)\n",
    "            \n",
    "            if logits is not None and labels is not None:\n",
    "                \n",
    "                all_logits_mc.append(logits)\n",
    "                all_labels_mc.append(labels)\n",
    "\n",
    "        if not all_logits_mc:\n",
    "            print('no valid predcition found for MC sampling')\n",
    "            return None\n",
    "\n",
    "        \n",
    "        all_logits = torch.cat(all_logits_mc , dim = 0)\n",
    "        all_labels = torch.cat(all_labels_mc , dim = 0).long()\n",
    "\n",
    "        \n",
    "        \n",
    "        nll_criterion = nn.CrossEntropyLoss().cuda()\n",
    "        ece_criterion = _ECE_criterion().cuda()\n",
    "        \n",
    "        ece1 = ece_criterion(all_logits , all_labels.squeeze(1))\n",
    "        nll1 = nll_criterion(all_logits , all_labels.squeeze(1))\n",
    "        print(f'ECE after MC sampling is : {ece1}')\n",
    "        print(f'NLL after MC sampling is : {nll1}')\n",
    "        print(f'improvement in ECE is : {((ece_standard - ece1)/ece_standard)*100}')\n",
    "\n",
    "        \n",
    "\n",
    "        return ece_standard , ece\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "    def _match_targets_to_outputs(self, outputs, targets):  # for each image \n",
    "        \n",
    "        labels = []\n",
    "        logits  = []\n",
    "    \n",
    "\n",
    "        logits_for_nms = outputs.clone()  # Clone to avoid modifying original logits\n",
    "        logits_for_nms = logits_for_nms.unsqueeze(0).transpose(-1, -2)  # Add batch dimension and transpose to match expected shape\n",
    "        confidence = torch.sigmoid(logits_for_nms[: , 4:14 , :]  )\n",
    "        bbox = logits_for_nms[: , 0:4 , :]   # Extract bounding box coordinates (x, y, x, y)\n",
    "        combined = torch.cat((bbox , confidence) , dim = 1)  # Remove batch dimension if present\n",
    "\n",
    "        nms_detections = non_max_suppression(combined, conf_thres=0.25,nc = 10, iou_thres=0.45, classes=None, agnostic=False, max_det=300 , in_place=False , return_idxs=True)\n",
    "\n",
    "      \n",
    "\n",
    "        original_indices = nms_detections[1][0] # Get the original indices of detections before NMS\n",
    "        \n",
    "\n",
    "        if len(nms_detections[0][0]) == 0:\n",
    "            return None, None\n",
    "            \n",
    "        pred_bboxes_xyxy = nms_detections[0][0][..., :4]  # Extract bounding boxes (x, y,x, y)\n",
    "        targets_bboxes = targets['bboxes']   #[N , 4]\n",
    "\n",
    "        targets_bboxes_xyxy = torch.cat([targets_bboxes[: , :2]- targets_bboxes[: , 2:4]/2 , targets_bboxes[: , :2]+ targets_bboxes[: , 2:4]/2], dim = 1)\n",
    "        \n",
    "        image_height, image_width = 640, 640  # Replace with your image size\n",
    "        # Normalize bounding boxes to [0, 1] range\n",
    "        pred_bboxes_xyxy[:, 0] /= image_width   # Normalize x\n",
    "        pred_bboxes_xyxy[:, 1] /= image_height  # Normalize y\n",
    "        \n",
    "        pred_bboxes_xyxy[:, 2] /= image_width   # Normalize x2\n",
    "        pred_bboxes_xyxy[:, 3] /= image_height  # Normalize y2\n",
    "        \n",
    "      \n",
    "        \n",
    "\n",
    "        iou_matrix = box_iou(targets_bboxes_xyxy, pred_bboxes_xyxy)   # N , M\n",
    "        \n",
    "       \n",
    "        \n",
    "        max_iou, max_iou_index = torch.max(iou_matrix , dim = 1)   # shape (N , )  # which detection index in nms has the maximum iou with each target\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(max_iou_index)):\n",
    "            if iou_matrix[i , max_iou_index[i]] > 0.60:\n",
    "               \n",
    "                labels.append(targets['cls'][i])\n",
    "                \n",
    "                 # Use the original index to get logits from the original outputs\n",
    "                original_detection_idx = original_indices[max_iou_index[i]]\n",
    "                logits.append(outputs[original_detection_idx , 4:14])\n",
    "\n",
    "            \n",
    "\n",
    "        print(f\"Number of matched logits: {len(logits)}\")\n",
    "        print(f\"Number of matched labels: {len(labels)}\")\n",
    "        if len(logits) == 0:\n",
    "            \n",
    "            return None, None \n",
    "        \n",
    "\n",
    "        logits= torch.stack(logits , dim = 0) if len(logits)>0 else None\n",
    "        labels= torch.stack(labels , dim = 0) if len(labels)>0 else None        \n",
    "        \n",
    "            \n",
    "        return logits  , labels\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = YOLO('best-with-dropout-layer.pt')\n",
    "\n",
    "#model = add_dropout_to_model( model,p=0.1)\n",
    "\n",
    "#dropout_model = YOLOWithDropout(model , n_samples = 5)\n",
    "\n",
    "#found = dropout_model.enable_dropout()\n",
    "#print('found is : ',found)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_model = YOLOWithDropout(model, n_samples=5)\n",
    "\n",
    "\n",
    "\n",
    "#dropout_model.evaluate_dropout(valid_loader)\n",
    "dropout_model.evaluate_dropout(valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
